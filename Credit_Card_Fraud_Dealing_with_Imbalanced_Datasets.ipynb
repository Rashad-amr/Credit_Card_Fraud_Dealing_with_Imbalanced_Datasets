{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize': [10, 10]}, font_scale=1.3)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Moutaz\\\\Downloads\\\\dataset\\\\creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT Frauds  99.827251436938 % of dataset\n",
      "Frauds  0.1727485630620034 % of dataset\n"
     ]
    }
   ],
   "source": [
    "print('NOT Frauds ', df['Class'].value_counts()[0]*100/len(df),'% of dataset')\n",
    "print('Frauds ', df['Class'].value_counts()[1]*100/len(df),'% of dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1f7c4633548>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Class', data=df, palette='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note   :\n",
    "  we can see there is skew in the data : 99.8 % of the data not fraud and 0.17% fraud \n",
    "  so we deal with imblanced class which mean we need to resample data before we create our model to predict\n",
    "  if we go before we deal with this imblanced class our model will be overfiting the data and we will get high accuracy which \n",
    "  will be miss leading cause the model will ingore miniorty (fraud) and focus majorty (not fraud) which mean we need\n",
    "  to focus on recall and persicion and f1 score ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data we have scaled from the source except (Time ,Amount) so we will scale them before we go "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =RobustScaler()\n",
    "df['Time']=scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "df['Amount']=scaler.fit_transform(df['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>1.783274</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>-0.269825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>4.983721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>1.418291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0.670579</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0 -0.994983 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1 -0.994983  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2 -0.994972 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3 -0.994972 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4 -0.994960 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "\n",
       "         V7        V8        V9  ...       V21       V22       V23       V24  \\\n",
       "0  0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928   \n",
       "1 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4  0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28    Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  1.783274      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724 -0.269825      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  4.983721      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  1.418291      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153  0.670579      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now all data scaled\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note :\n",
    " now all data scaled but still imbalnced so we will split data to train and test sets and take train set and resample it (up sample ) and train our model on it then test our model on test set so we make sure he didn't see this data before and test set still imbalnced so we make sure from our model whether he do will on test set or not and see whether it will overfit or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spliting data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x=df.drop('Class',axis=1)\n",
    "y= df['Class']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=27)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(213605, 30)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71202, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264873</th>\n",
       "      <td>0.903934</td>\n",
       "      <td>-0.395578</td>\n",
       "      <td>1.489129</td>\n",
       "      <td>-0.833442</td>\n",
       "      <td>-0.224271</td>\n",
       "      <td>0.369444</td>\n",
       "      <td>-1.453886</td>\n",
       "      <td>0.796593</td>\n",
       "      <td>-0.060403</td>\n",
       "      <td>0.338270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231624</td>\n",
       "      <td>0.955194</td>\n",
       "      <td>-0.172092</td>\n",
       "      <td>-0.041050</td>\n",
       "      <td>-0.313444</td>\n",
       "      <td>-0.174301</td>\n",
       "      <td>0.064657</td>\n",
       "      <td>-0.036960</td>\n",
       "      <td>-0.269126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163821</th>\n",
       "      <td>0.370599</td>\n",
       "      <td>1.950487</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>-1.761814</td>\n",
       "      <td>1.232470</td>\n",
       "      <td>0.523175</td>\n",
       "      <td>-0.650657</td>\n",
       "      <td>0.504231</td>\n",
       "      <td>-0.200857</td>\n",
       "      <td>0.116805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086306</td>\n",
       "      <td>0.326297</td>\n",
       "      <td>-0.068839</td>\n",
       "      <td>-0.416589</td>\n",
       "      <td>0.426044</td>\n",
       "      <td>-0.486299</td>\n",
       "      <td>-0.031266</td>\n",
       "      <td>-0.072543</td>\n",
       "      <td>0.229721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72083</th>\n",
       "      <td>-0.354034</td>\n",
       "      <td>1.105167</td>\n",
       "      <td>-0.166253</td>\n",
       "      <td>0.569520</td>\n",
       "      <td>0.681043</td>\n",
       "      <td>-0.259189</td>\n",
       "      <td>0.642792</td>\n",
       "      <td>-0.437034</td>\n",
       "      <td>0.356746</td>\n",
       "      <td>0.441417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009073</td>\n",
       "      <td>0.293023</td>\n",
       "      <td>-0.028688</td>\n",
       "      <td>-0.242206</td>\n",
       "      <td>0.389813</td>\n",
       "      <td>0.482852</td>\n",
       "      <td>0.010705</td>\n",
       "      <td>-0.008399</td>\n",
       "      <td>-0.293440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196949</th>\n",
       "      <td>0.553096</td>\n",
       "      <td>1.805238</td>\n",
       "      <td>0.961264</td>\n",
       "      <td>-1.717212</td>\n",
       "      <td>4.094625</td>\n",
       "      <td>0.938666</td>\n",
       "      <td>-0.227785</td>\n",
       "      <td>0.152911</td>\n",
       "      <td>0.066753</td>\n",
       "      <td>-1.073784</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.137875</td>\n",
       "      <td>-0.450959</td>\n",
       "      <td>0.098530</td>\n",
       "      <td>-0.662272</td>\n",
       "      <td>-0.150154</td>\n",
       "      <td>-0.098852</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>0.017622</td>\n",
       "      <td>0.222036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126213</th>\n",
       "      <td>-0.079101</td>\n",
       "      <td>0.835421</td>\n",
       "      <td>-1.191847</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.586101</td>\n",
       "      <td>-1.236663</td>\n",
       "      <td>0.194617</td>\n",
       "      <td>-0.532404</td>\n",
       "      <td>0.061561</td>\n",
       "      <td>-0.734344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072349</td>\n",
       "      <td>-0.109154</td>\n",
       "      <td>-0.308356</td>\n",
       "      <td>0.011968</td>\n",
       "      <td>0.461350</td>\n",
       "      <td>-0.244810</td>\n",
       "      <td>0.031845</td>\n",
       "      <td>0.060910</td>\n",
       "      <td>3.004262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "264873  0.903934 -0.395578  1.489129 -0.833442 -0.224271  0.369444 -1.453886   \n",
       "163821  0.370599  1.950487  0.002312 -1.761814  1.232470  0.523175 -0.650657   \n",
       "72083  -0.354034  1.105167 -0.166253  0.569520  0.681043 -0.259189  0.642792   \n",
       "196949  0.553096  1.805238  0.961264 -1.717212  4.094625  0.938666 -0.227785   \n",
       "126213 -0.079101  0.835421 -1.191847  0.578455  0.586101 -1.236663  0.194617   \n",
       "\n",
       "              V7        V8        V9  ...       V21       V22       V23  \\\n",
       "264873  0.796593 -0.060403  0.338270  ...  0.231624  0.955194 -0.172092   \n",
       "163821  0.504231 -0.200857  0.116805  ...  0.086306  0.326297 -0.068839   \n",
       "72083  -0.437034  0.356746  0.441417  ...  0.009073  0.293023 -0.028688   \n",
       "196949  0.152911  0.066753 -1.073784  ... -0.137875 -0.450959  0.098530   \n",
       "126213 -0.532404  0.061561 -0.734344  ... -0.072349 -0.109154 -0.308356   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "264873 -0.041050 -0.313444 -0.174301  0.064657 -0.036960 -0.269126      0  \n",
       "163821 -0.416589  0.426044 -0.486299 -0.031266 -0.072543  0.229721      0  \n",
       "72083  -0.242206  0.389813  0.482852  0.010705 -0.008399 -0.293440      0  \n",
       "196949 -0.662272 -0.150154 -0.098852 -0.000030  0.017622  0.222036      0  \n",
       "126213  0.011968  0.461350 -0.244810  0.031845  0.060910  3.004262      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will let X_test ,Y_test  for testing resualt and to be no leaking in information\n",
    "train_data=pd.concat([x_train,y_train],axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# Up sample the minority ( fraud ) to be equal to majority ( not fraud )\n",
    "not_fraud = train_data[train_data['Class']==0]\n",
    "fraud=train_data[train_data['Class']==1]\n",
    "\n",
    "fraud_upsampled=resample(fraud,n_samples=len(not_fraud),replace=True,random_state=27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_sampled_data=pd.concat([not_fraud,fraud_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426490, 31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_sampled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=up_sampled_data.drop('Class',axis=1)\n",
    "y_train=up_sampled_data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now we will train the model and choose the best algorithm , note accuracy score maybe be missleading so we will use F1 score ,recall ,precision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model=LogisticRegression()\n",
    "log_model.fit(x_train,y_train)\n",
    "y_pred=log_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[69544,  1526],\n",
       "       [   15,   117]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(69544 true postive) and (1526 false/postive type 1 error ) \n",
    "(15 false/negative type 2 error) and (117 true/ negative )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9783573495126542"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     71070\n",
      "           1       0.07      0.89      0.13       132\n",
      "\n",
      "    accuracy                           0.98     71202\n",
      "   macro avg       0.54      0.93      0.56     71202\n",
      "weighted avg       1.00      0.98      0.99     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying k-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.19 %\n",
      "Standard Deviation: 0.08 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=log_model,X=x_train,y=y_train,cv=10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model=KNeighborsClassifier()\n",
    "knn_model.fit(x_train,y_train)\n",
    "y_pred=knn_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[71036,    34],\n",
       "       [   20,   112]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(71036 true postive) and (34 false/postive type 1 error ) \n",
    "(20 false/negative type 2 error) and (112 true/ negative )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992415943372377"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71070\n",
      "           1       0.77      0.85      0.81       132\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.88      0.92      0.90     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.96 %\n",
      "Standard Deviation: 0.01 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator=knn_model,X=x_train,y=y_train,cv=10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_model = SVC()\n",
    "svm_model.fit(x_train,y_train)\n",
    "y_pred =svm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9926687452599646"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70567,   503],\n",
       "       [   19,   113]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(70567 true postive) and (503 false/postive type 1 error ) \n",
    "(19 false/negative type 2 error) and (113 true/ negative )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     71070\n",
      "           1       0.18      0.86      0.30       132\n",
      "\n",
      "    accuracy                           0.99     71202\n",
      "   macro avg       0.59      0.92      0.65     71202\n",
      "weighted avg       1.00      0.99      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.58 %\n",
      "Standard Deviation: 0.09 %\n"
     ]
    }
   ],
   "source": [
    "accuracies =cross_val_score(estimator=svm_model,X=x_train,y=y_train,cv=10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xg_model = XGBClassifier()\n",
    "xg_model.fit(x_train, y_train)\n",
    "y_pred=xg_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70776,   294],\n",
       "       [   18,   114]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(70776 true postive) and (294 false/postive type 1 error ) \n",
    "(18 false/negative type 2 error) and (114 true/ negative )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9956181006151512"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71070\n",
      "           1       0.28      0.86      0.42       132\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.64      0.93      0.71     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.78 %\n",
      "Standard Deviation: 0.04 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = xg_model, X = x_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
